{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b41c1cc",
   "metadata": {
    "id": "8b41c1cc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "X_VqUygjst8f",
   "metadata": {
    "id": "X_VqUygjst8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1efd29",
   "metadata": {
    "id": "ae1efd29"
   },
   "outputs": [],
   "source": [
    "class LazyLoadDataset(Dataset):\n",
    "    def __init__(self, path, train=True, transform=None):\n",
    "        self.transform = transform\n",
    "        if train:\n",
    "            path = path + \"train\\\\\" \n",
    "        else:\n",
    "            path = path + \"test\\\\\"\n",
    "        \n",
    "        self.pathX = path + \"X\\\\\"\n",
    "        self.pathY = path + \"Y\\\\\"\n",
    "        \n",
    "        self.data = os.listdir(self.pathX)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        f = self.data[idx]\n",
    "        \n",
    "        # X\n",
    "        # read rgb images\n",
    "        \n",
    "        img0 = cv2.imread(self.pathX + f + \"\\\\rgb\\\\0.png\")\n",
    "        img1 = cv2.imread(self.pathX + f + \"\\\\rgb\\\\1.png\")\n",
    "        img2 = cv2.imread(self.pathX + f + \"\\\\rgb\\\\2.png\")\n",
    "        \n",
    "        img = np.vstack((img0, img1, img2))\n",
    "        \n",
    "        # read depth images\n",
    "        depth = np.load(self.pathX + f + \"\\\\depth.npy\")\n",
    "        \n",
    "        depth = np.divide(depth, 1000)\n",
    "                \n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # read field ID\n",
    "        field_id = pkl.load(open(self.pathX + f + \"\\\\field_id.pkl\", \"rb\"))\n",
    "        \n",
    "        # Y\n",
    "        Y = np.load(self.pathY + f + \".npy\")\n",
    "        \n",
    "        return (img0, img1, img2, img, depth, field_id), Y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f70336ba",
   "metadata": {
    "id": "f70336ba"
   },
   "outputs": [],
   "source": [
    "input_size  = 224*224     # images are 224x224 pixels for each image\n",
    "output_size = 12          # (x,y,z) coordinates for the 4 fingers\n",
    "\n",
    "dataset = LazyLoadDataset(\"C:\\\\Users\\\\jason_00wr0b7\\\\Downloads\\\\lazydata\\\\lazydata\\\\\", train=True,\n",
    "                               transform = transforms.ToTensor())\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "# split train dataset into train and test data\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=34, shuffle=False)\n",
    "\n",
    "# data loader for calculating normalization statistics\n",
    "normal_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb6e8fe1",
   "metadata": {
    "id": "cb6e8fe1"
   },
   "outputs": [],
   "source": [
    "(img0, img1, img2, img, depth, field_id), Y = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55ev3JZmwgd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1670033977002,
     "user": {
      "displayName": "Jason Zhiyuan Zhang",
      "userId": "13688260570360632326"
     },
     "user_tz": 300
    },
    "id": "f55ev3JZmwgd",
    "outputId": "a28145ee-49e8-4481-a601-3c4019889489"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02667237,  0.05455598,  0.12987244,  0.02514074, -0.00112136,\n",
       "        0.13262471,  0.03066019, -0.05429448,  0.12896113,  0.05547796,\n",
       "        0.01084437, -0.06837047])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lRg4iPR1mwwc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1670033979089,
     "user": {
      "displayName": "Jason Zhiyuan Zhang",
      "userId": "13688260570360632326"
     },
     "user_tz": 300
    },
    "id": "lRg4iPR1mwwc",
    "outputId": "db22d7a4-811d-41ad-e97b-2b7c0e672c77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3320'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcaaa727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std for 0 mean unit std normalization\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    mean_img0 = 0\n",
    "    std_img0 = 0\n",
    "    mean_img1 = 0\n",
    "    std_img1 = 0\n",
    "    mean_img2 = 0\n",
    "    std_img2 = 0\n",
    "    mean_depth = 0\n",
    "    std_depth = 0\n",
    "    \n",
    "    for batch_idx, ((img0, img1, img2, img, depth, field_id), Y) in enumerate(loader):\n",
    "        mean_img0 += img0.mean()\n",
    "        mean_img1 += img1.mean()\n",
    "        mean_img2 += img2.mean()\n",
    "        mean_depth += depth.mean()\n",
    "        std_img0 += img0.std()\n",
    "        std_img1 += img1.std()\n",
    "        std_img2 += img2.std()\n",
    "        std_depth += depth.std()\n",
    "        \n",
    "    mean_img0 /= dataset_size\n",
    "    std_img0 /= dataset_size\n",
    "    mean_img1 /= dataset_size\n",
    "    std_img1 /= dataset_size\n",
    "    mean_img2 /= dataset_size\n",
    "    std_img2 /= dataset_size\n",
    "    mean_depth /= dataset_size\n",
    "    std_depth /= dataset_size\n",
    "    \n",
    "    return mean_img0, mean_img1, mean_img2, mean_depth, std_img0, std_img1, std_img2, std_depth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5982083",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_img0, mean_img1, mean_img2, mean_depth, std_img0, std_img1, std_img2, std_depth = get_mean_std(normal_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f6b99e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4161)\n",
      "tensor(0.2040)\n",
      "tensor(0.9125)\n",
      "tensor(0.8012)\n"
     ]
    }
   ],
   "source": [
    "print(mean_img0)\n",
    "print(std_img0)\n",
    "print(mean_depth)\n",
    "print(std_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd57c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom RMSE Loss function\n",
    "\n",
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss,self).__init__()\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39bdfce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization transforms\n",
    "\n",
    "t0 = transforms.Compose([transforms.Normalize((mean_img0,), (std_img0,)),\n",
    "                        \n",
    "                        ])\n",
    "t1 = transforms.Compose([transforms.Normalize((mean_img1,), (std_img1,)),\n",
    "                        \n",
    "                        ])\n",
    "t2 = transforms.Compose([transforms.Normalize((mean_img2,), (std_img2,)),\n",
    "                        \n",
    "                        ])\n",
    "t_depth = transforms.Compose([transforms.Normalize((mean_depth,), (std_depth,)),\n",
    "                        \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pr5AD-PMwOu2",
   "metadata": {
    "id": "pr5AD-PMwOu2"
   },
   "outputs": [],
   "source": [
    "# define train and test functions\n",
    "\n",
    "loss_fn = RMSELoss()\n",
    "\n",
    "def train(epoch, model, optimizer, multiplier):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "\n",
    "    Args:\n",
    "        epoch (int): current epoch\n",
    "        model (nn.Module): model to train\n",
    "        optimizer (torch.optim): optimizer to use\n",
    "        multipier (int): value to multiply ground truth and prediction by\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, ((img0, img1, img2, img, depth, field_id), Y) in enumerate(train_loader):   \n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # apply transformations\n",
    "        img0 = t0(img0)\n",
    "        img1 = t1(img1)\n",
    "        img2 = t2(img2)\n",
    "        depth = t_depth(depth)\n",
    "                \n",
    "        # send to device\n",
    "        img0 = img0.to(device)\n",
    "        img1 = img1.to(device)\n",
    "        img2 = img2.to(device)\n",
    "        depth = depth.to(device)\n",
    "        \n",
    "        # obtain output, multiply ground truth by multiplier\n",
    "        output = model(img0, img1, img2, depth) \n",
    "        output = torch.mul(output, multiplier)\n",
    "        Y = torch.mul(Y, multiplier)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_fn(output.double(), Y)\n",
    "                                        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(output[0, :])\n",
    "            print(Y[0, :])\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(img), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model):\n",
    "    \"\"\"\n",
    "    Test the model\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): model to test\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    for batch_idx, ((img0, img1, img2, img, depth, field_id), Y) in enumerate(test_loader):\n",
    "        \n",
    "        # apply transformations\n",
    "        img0 = t0(img0)\n",
    "        img1 = t1(img1)\n",
    "        img2 = t2(img2)\n",
    "        depth = t_depth(depth)\n",
    "        \n",
    "        # send to device\n",
    "        img0 = img0.to(device)\n",
    "        img1 = img1.to(device)\n",
    "        img2 = img2.to(device)\n",
    "        depth = depth.to(device)\n",
    "        \n",
    "        output = model(img0, img1, img2, depth)\n",
    "        \n",
    "        loss = loss_fn(output, Y)\n",
    "        test_loss += loss.item() # sum up batch loss  \n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(output[0, :])\n",
    "            print(Y[0, :])\n",
    "            print('Test Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(img), len(test_loader.dataset),\n",
    "                100. * batch_idx / len(test_loader), loss.item()))\n",
    "        \n",
    "    test_loss /= batch_idx + 1\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(\n",
    "        test_loss,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ed3f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_layers1, hidden_layers2, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Setup resnet18s feature extractor\n",
    "        m0 = models.resnet18(pretrained=False)\n",
    "        m0.fc = nn.Identity()\n",
    "        self.resnet18_img0 = m0\n",
    "        \n",
    "        m1 = models.resnet18(pretrained=False)\n",
    "        m1.fc = nn.Identity()\n",
    "        self.resnet18_img1 = m1\n",
    "        \n",
    "        m2 = models.resnet18(pretrained=False)\n",
    "        m2.fc = nn.Identity()\n",
    "        self.resnet18_img2 = m2\n",
    "        \n",
    "        m3 = models.resnet18(pretrained=False)\n",
    "        m3.fc = nn.Identity()\n",
    "        self.resnet18_depth = m3\n",
    "                \n",
    "        # resnet18 provide (1000, ) features x 4 images concatenated together \n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512 * 4, hidden_layers1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_layers1, hidden_layers1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layers1, hidden_layers2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layers2, hidden_layers2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layers2, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img0, img1, img2, depth):\n",
    "        # have resnet18s process images seperately\n",
    "        y0 = self.resnet18_img0(img0)\n",
    "        y1 = self.resnet18_img1(img1)\n",
    "        y2 = self.resnet18_img2(img2)\n",
    "        y_depth = self.resnet18_depth(depth)\n",
    "       \n",
    "        # combine resnet outputs with full connected layers\n",
    "        y = torch.concat([y0, y1, y2, y_depth], dim=-1)\n",
    "        \n",
    "        return self.fc_layers(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c01a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_layer, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Setup resnet18s feature extractor\n",
    "        m0 = models.resnet18(pretrained=False)\n",
    "        m0.fc =  nn.Sequential(\n",
    "            nn.Linear(512, hidden_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer, output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.resnet_img0 = m0\n",
    "        \n",
    "        m1 = models.resnet18(pretrained=False)\n",
    "        m1.fc = nn.Sequential(\n",
    "            nn.Linear(512, hidden_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer, output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.resnet_img1 = m1\n",
    "        \n",
    "        m2 = models.resnet18(pretrained=False)\n",
    "        m2.fc = nn.Sequential(\n",
    "            nn.Linear(512, hidden_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer, output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.resnet_img2 = m2\n",
    "        \n",
    "        m3 = models.resnet18(pretrained=False)\n",
    "        m3.fc = nn.Sequential(\n",
    "            nn.Linear(512, hidden_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer, output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.resnet_depth = m3\n",
    "                \n",
    "        # resnet18 provide (12, ) features x 4 images concatenated together \n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(output_size * 4, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img0, img1, img2, depth):\n",
    "        # have resnet18s process images seperately\n",
    "        y0 = self.resnet_img0(img0)\n",
    "        y1 = self.resnet_img1(img1)\n",
    "        y2 = self.resnet_img2(img2)\n",
    "        y_depth = self.resnet_depth(depth)\n",
    "       \n",
    "        # combine resnet outputs with full connected layers\n",
    "        y = torch.concat([y0, y1, y2, y_depth], dim=-1)\n",
    "        \n",
    "        return self.fc_layers(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a7c1c91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ls9nlyjIxNKR",
    "outputId": "696b971c-2bc5-4266-8ccf-7266d8fc52c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN2(\n",
       "  (resnet_img0): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=12, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (resnet_img1): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=12, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (resnet_img2): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=12, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (resnet_depth): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=12, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=48, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intialize CNN\n",
    "\n",
    "hidden_layers1 = 500\n",
    "hidden_layers2 = 100\n",
    "hidden_layers = 100\n",
    "\n",
    "model = CNN2(hidden_layers, output_size)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "baba27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=10 ** (-4), momentum = 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e46a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  23.9962, -123.7691,  -88.4072,   36.4003,   73.3948, -111.6677,\n",
      "          54.0759,  149.2507, -150.4455,   -2.0535,   14.1535,  -36.7543],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([ 49.5241,  51.3114, 120.7183,  65.3726,  -2.5752,  96.9856,  71.9823,\n",
      "        -48.1654,  73.5571,  56.3476, -17.6821, -55.3574], dtype=torch.float64)\n",
      "Train Epoch: 0 [0/2716 (0%)]\tLoss: 135.065397\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([ 19.1967,  54.7317, 130.7740,  72.8490,  -3.0375, 109.3590,  89.8884,\n",
      "        -31.0676,   0.2593,  68.7539,  68.9863,  -6.8523], dtype=torch.float64)\n",
      "Train Epoch: 0 [640/2716 (23%)]\tLoss: nan\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([ 19.6957,  54.7196, 131.4918,  87.7424,   3.8980,  96.7588,  52.7440,\n",
      "        -48.7357,  -9.9186,  67.4000,  36.7304, -27.9597], dtype=torch.float64)\n",
      "Train Epoch: 0 [1280/2716 (47%)]\tLoss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# train and test model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     test(model)\n",
      "Cell \u001b[1;32mIn[13], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch, model, optimizer, multiplier)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# calculate loss\u001b[39;00m\n\u001b[0;32m     39\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output\u001b[38;5;241m.\u001b[39mdouble(), Y)\n\u001b[1;32m---> 41\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and test model\n",
    "\n",
    "for epoch in range(0, 3):\n",
    "    \n",
    "    train(epoch, model, optimizer, 1000)\n",
    "    test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4a0d27e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to csv file submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "outfile = 'submission.csv'\n",
    "\n",
    "output_file = open(outfile, 'w')\n",
    "\n",
    "titles = ['ID', 'FINGER_POS_1', 'FINGER_POS_2', 'FINGER_POS_3', 'FINGER_POS_4', 'FINGER_POS_5', 'FINGER_POS_6',\n",
    "         'FINGER_POS_7', 'FINGER_POS_8', 'FINGER_POS_9', 'FINGER_POS_10', 'FINGER_POS_11', 'FINGER_POS_12']\n",
    "preds = []\n",
    "    \n",
    "test_data = torch.load('C:\\\\Users\\\\jason_00wr0b7\\\\Downloads\\\\finals_data\\\\test\\\\test\\\\testX.pt')\n",
    "file_ids = test_data[-1]\n",
    "rgb_data = test_data[0]\n",
    "depth_data = test_data[1]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "for i, data in enumerate(rgb_data):\n",
    "    # Please remember to modify this loop, input and output based on your model/architecture\n",
    "    data = torch.div(data, 255)\n",
    "    depth = torch.div(depth_data[i], 1000)\n",
    "    depth = depth.reshape(1,3,224,224)\n",
    "    \n",
    "    img0 = t0(data[0:1, :, :, :])\n",
    "    img1 = t1(data[1:2, :, :, :])\n",
    "    img2 = t2(data[2:3, :, :, :])\n",
    "    depth = t_depth(depth)\n",
    "    \n",
    "    output = model(img0, img1, img2, depth)\n",
    "    preds.append(output[0].cpu().detach().numpy())\n",
    "\n",
    "df = pd.concat([pd.DataFrame(file_ids), pd.DataFrame.from_records(preds)], axis = 1, names = titles)\n",
    "df.columns = titles\n",
    "df.to_csv(outfile, index = False)\n",
    "print(\"Written to csv file {}\".format(outfile))\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c342d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
